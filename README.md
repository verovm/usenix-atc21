# Introduction

This repository contains all materials used for experiments in the paper:

**Yeonsoo Kim, Seongho Jeong, Kamil Jezek, Bernd Burgstaller, and Bernhard Scholz**: _An Off-The-Chain Execution Environment for Scalable Testing and Profiling of Smart Contracts_,  ATC Usenix 2021

These materials may be used for relplication studies, follow-up research, etc. The following sections contain information for three use cases from the paper. 

# Environment Preparation

All three use cases require pre-recorded substate database. This databse can be either generated by the recorder tool from the blockchain, or we provide a snapshot for download. 

## Building Go-Ethereum (Geth)

Our substate recorder/replayer and use cases are implemented based on go-ethereum (geth). Please follow _Building the source_ section of [Geth's README](./go-ethereum/README.md) to build our tools.

## Sync and Export Blockchain in Files

```bash
# build geth
cd ./go-ethereum/
make geth

# press ctrl-c to stop geth sync when it reached the desired block height
./build/bin/geth --datadir /path/to/geth.datadir --syncmode fast --gcmode full

# export from block 2,000,001 to 3,000,000 (total 1M blocks)
./build/bin/geth --datadir /path/to/geth.datadir --syncmode fast --gcmode full 2-3M.blockchain 2000001 3000000
```

## Generate Database

Substate recorder is implemented by modifying `geth import` command which processes blockchain files exported from Geth full node. To generate substate database, import a blockchain file exported from a Geth full node to our substate recorder. Substate recorder will create substate DB in `./stage1-substate/` directory.

```bash
# build recorder
cd ./record-replay/go-ethereum/
make geth

# record substates in ./stage1-substate/
./build/bin/geth --datadir /path/to/recorder.datadir import /path/to/0-9M.blockchain
```

## Pre-existing Blockchain and Database Snapshot
* Exported blockchain files (0-1M.blockchain, 1-2M.blockchain, ...): [gdrive directory](https://drive.google.com/drive/folders/132VLKpxPfulbcg36hiY6C1Sef3yXAirG?usp=sharing) (104 GB)
* Exported blockchain file of 9M blocks (0-9M.blockchain): [gdrive download](https://drive.google.com/file/d/1VoOtMlhcaT_CeVulP8VQ-TpHFZ7eVbqy/view?usp=sharing) (104 GB)
* Substate DB of 9M blocks (stage1-substate-0-9M.tar.zst): [gdrive download](https://drive.google.com/file/d/1jl6vdMea5ROKdrTUJUk8lh5NL48Do9xJ/view?usp=sharing) (139 GB, decompressed size: 285GB)

```bash
# untar substate DB
tar -xavf stage1-substate-0-9M.tar.zst
mv stage1-substate-0-9M stage1-substate
```

# Scalability of Substate Replayer

Following experiments provide results of Table 2-3 and Figure 6 in section 5.1 Scalability of Substate Replayer which compares time and space required to replay transactions in 9M blocks using Geth full node and substate replayer.

## Geth Full Node - Time and Space

This experiment measures time and space to replay transactions with Geth full node in Table 2-3. To measure single thread performance in block processing, `--cache.noprefetch` option is given. Block import time and maximum Geth database size of each 1M blocks will be saved in `.log` files.

```bash
# build geth
cd ./go-ethereum/
make geth

# measure geth block import time and size
./build/bin/geth --datadir geth.ethereum --cache.noprefetch import 0-1M.blockchain 2>&1 | tee -a geth-0-1M.log
du -s geth.ethereum >> geth-0-1M.log
./build/bin/geth --datadir geth.ethereum --cache.noprefetch import 8-9M.blockchain 2>&1 | tee -a geth-1-2M.log
du -s geth.ethereum >> geth-1-2M.log
...
```

## Substate Replayer - Time

This experiment measures execution time of single- and multi-threaded substate replayer in Table 3 and Figure 6. Substate replayer has `evm transition-substate` command (`evm t8n-substate`) that loads substates of a given block range from `./stage1-substate/` and replay transactions. If substate replayer finds that the replay output is different from the expected output, it will returns an error immediately.

For example, if you want to replay trasnactions from 46147 to 50000 with 8 replay threads:
```bash
evm t8n-substate 46147 50000 --workers 8
```

For more command line options, run `evm t8n-substate --help`

[evm-t8n-substate-0-9M.sh](./record-replay/evm-t8n-substate-0-9M.sh) is a bash script that runs substate replayer with different numbers of threads.

[evm-t8n-substate-csv.py](./record-replay/evm-t8n-substate-csv.py) is a python3 script that collects output log files of `evm-t8n-substate-0-9M.sh` and print data in CSV format.

```bash
# build substate replayer (evm)
cd ./record-replay/go-ethereum/
make all

# measure replayer performance and print data in CSV
cd ../
./evm-t8n-substate-0-9M.sh
./evm-t8n-substate-csv.py
```

## Substate Replayer - Space

This experiment measures space required to replay transactions with substate replayer in Table 2. Substate replayer has `evm dump-substate` that reads `./stage1-substate/` and creates a database copy with substates found in a given range of blocks.

For example, to measure space required to replay transactions in 2-3M blocks,
```bash
# build substate replayer (evm)
cd ./record-replay/go-ethereum/
make all

# copy substates of 2-3M blocks and measure database size
cd ../
evm dump-substate ./stage1-substate-2-3M/ 2000001 3000000
du -s ./stage1-substate-2-3M/
```

# Metrics Use Case

The metrics use case analyzes transactions by generating a graph of instruction flow. It will count the number of live instructions and live gases.
You can produce a result of metrics as a CSV file for 9M blocks:
```
evm t8n-substate 1 9000000 --skip-transfer-txs --skip-create-txs --log-file result.csv
```
If you want to visualize a value graph, following command will generate a PNG image for the first transaction executed in the block 2000000.
```
evm t8n-substate 2000000 2000000 --workers 1 --graph
```

# Contract Fuzzer Use Case

This experiment provide results for paper Section 5.3 Fuzzer Use Case. This repository contais two variants of ContractFuzzer - an original version, and our fork that enables transaction replay. 

The experiment requires 
* the sub-state database, 
* contracs' ABIs, 
* addresses mapping (address-to-substate/): [gdrive download](https://drive.google.com/file/d/13eTEpu7Bt1XRpKDFFHYNhy_phwuLujGV/view?usp=sharing) (108 MB, decompressed size: 805 MB)
* [NodeJS Installation](https://nodejs.org/en/download/), 
* [Docker installation](https://docs.docker.com/get-docker/).

## Contracts' ABIs

The contract's ABIs can be obtained by the script:
```
cd ~/usenix-atc21/contract-fuzzer/substate-cf/contract_downloader/
./download_contracts.sh ~/address-to-substate/ ~/contracts 10
```
The parameters of the script tell (1) the directory with the addresses mappings (2) the output dir (3) the size of the batch, the ABIs will be grouped into - in the paper we have used 10. 

Notice that the script will try to download all available ABIs for the whole blockchain. It is possible to interrupt the script anytime earlier and continue the experiment on a smaller dataset. In the paper, we have dowloaed several tens of ABIs. 

## Build Docker Images

This repository contains docker images to simplify run of the experiments. Build the images by following commands:

```
cd ~/usenix-atc21/contract-fuzzer/original-cf/
docker build -t contractfuzzer-original-experiment .

cd ~/usenix-atc21/contract-fuzzer/substate-cf/
docker build -t contractfuzzer-experiment .

cd ~/usenix-atc21/contract-fuzzer/substate-cf/contract_experiments/
docker build -t cf-experiment-master  .
```

## Run the Experiment - Original Contract Fuzzer

Now the experiment may be triggered for the original contract fuzzer:
```
cd ~/usenix-atc21/contract-fuzzer/original-cf/contract_experiments/
```
Edit the ```docker-compose.yaml``` file via a text editor and update the following lines to contain correct paths on your system - absolute paths must be used (modify only the path before colon):
```
   - /opt/cf-experiments/contracts-original/:/contracts     # Directory with contracs's ABIs, must point to /absolute/path//usenix-atc21/contract-fuzzer/contracts-original
   - /opt/cf-experiments/address-to-substate/:/addresses    # Addresses mappings
   - /opt/cf-experiments/stage1-substate:/ContractFuzzer/stage1-substate/     # Substate database
```

The experiment may be now invoked via docker:
```
 docker swarm init
 docker stack deploy -c  docker-compose.yaml CF
 ```
 These commands run the experiment as docker services. 
 Now, periodically monitor logs, which will contain speed of executions, by using the following command: 
 ```
 docker service logs CF_master
 ```
 This will show for instance an output:
 ```
 CF_master.1  | Next task is 10 Index: 2/1165
 CF_master.1  | Speed:  diffTime: 4.0002, finishedTasks: 10, speed: 2.4998750062496873
 ```
 After some time of the experiment run, the value of the speed stabilises and it is used in the paper in Table 4: ContractFuzzer — performance improvements, first row.
 The running experiment may be interrupted by typing:
 ```
 docker stack rm CF
 ```
 ## Run the Experiment - Contract Fuzzer with Substate Reply
 
 To run the experiment, go to the directory 
 ```
 cd ~/usenix-atc21/contract-fuzzer/substate-cf/contract_experiments
 ```
 and repeat the same steps as in the previous experiments. Now the ContractFuzzer will use contracts data from the substate database via the Replay tool. 
 
 Edit the ```docker-compose.yaml``` file via a text editor and update again the paths (notice that the paths to contracts will be different than in the first experiment):
 
 ```
   - /opt/cf-experiments/contracts/:/contracts     # Directory with contracs's ABIs downloaded by the script above, must point to ABIs downloaded by the script /download_contracts.sh
   - /opt/cf-experiments/address-to-substate/:/addresses    # Addresses mappings
   - /opt/cf-experiments/stage1-substate:/ContractFuzzer/stage1-substate/     # Substate database 
```
 Furthermore, change the number of parallel executions. After each edit, run the experiment again. 
 
 ```
   deploy:
      replicas: 1    # Numner of parallel executions
 ```

The same as in the previous experiment, the speed is monitored and the results are used for Table 4: ContractFuzzer — performance improvements, second and next rows. The number of parallel tasks in the first column matches to the number of selected ```replicas```.

Notice that all replicas use the same sub-state database mounted via a file mount, and no testnet is needed. 

# Hard Fork Assesment Use Case

This experiment provides results of Table 5 in section 5.4 Hard Fork Assessment. This experiment assess hard forks by replaying transactions in the same context they were executed except the protocols changed by the new hard fork.

For example, to assess Byzantium hard fork activated at block 4,370,000:
```bash
evm replay-fork 1 4369999 --skip-transfer-txs --skip-create-txs --hard-fork 4370000
```

[replay-fork-0-9M.sh](./hard-fork/replay-fork-0-9M.sh) is a bash script to assess all hard forks activated before block 9,000,000 with CALL transactions (contract invocations) in initial 9M blocks.

```bash
# build evm for hard fork assessment
cd ./hard-fork/go-ethereum/
make all

# run hard fork assessments with 9M blocks
cd ../
./replay-fork-0-9M.sh
```

# usenix-atc21

1. go-ethereum/

Original go-ethereum v1.9.18 source code

2. record-replay/



